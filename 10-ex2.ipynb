{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce2f9ce-b674-46cf-94b9-e7e5bafe387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: [\"[Errno 2] The file to load file system plugin from does not exist.: '/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so'\"]\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: cannot open shared object file: No such file or directory']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d058d09b-dda7-4be9-b130-8d917419a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # The default batch size of keras.\n",
    "num_classes = 10  # Number of class for the dataset\n",
    "epochs = 100\n",
    "data_augmentation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730d0296-a9a3-4416-86d6-5e423b94d78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 26s 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65941db0-96f0-41ea-8a00-27e742fd46f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23001ffd-9382-4359-a41d-be1a2612ff9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "611de8c9-5bfa-46cc-8d50-35888b98a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data. Before we need to connvert data type to float for computation.\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices. This is called one hot encoding.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5228ab4b-b420-4416-a185-0a937832d4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 15, 15, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1180160   \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define the convnet\n",
    "model = Sequential()\n",
    "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# FLATTERN => DENSE => RELU => DROPOUT\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# a softmax classifier\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff38d9a5-3e6f-4e95-a153-7838598aee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad56774-3be8-4a14-b4aa-6661ba124838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 11:45:36.225218: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.8314 - accuracy: 0.3298 - val_loss: 1.5704 - val_accuracy: 0.4280\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.4951 - accuracy: 0.4620 - val_loss: 1.3401 - val_accuracy: 0.5209\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3536 - accuracy: 0.5168 - val_loss: 1.2332 - val_accuracy: 0.5639\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2508 - accuracy: 0.5580 - val_loss: 1.1372 - val_accuracy: 0.6047\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 1.1688 - accuracy: 0.5879 - val_loss: 1.1097 - val_accuracy: 0.6110\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.1025 - accuracy: 0.6121 - val_loss: 1.0459 - val_accuracy: 0.6296\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.0477 - accuracy: 0.6337 - val_loss: 0.9878 - val_accuracy: 0.6548\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.0076 - accuracy: 0.6477 - val_loss: 0.9259 - val_accuracy: 0.6756\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9684 - accuracy: 0.6623 - val_loss: 0.9276 - val_accuracy: 0.6784\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9343 - accuracy: 0.6748 - val_loss: 0.9015 - val_accuracy: 0.6843\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9038 - accuracy: 0.6851 - val_loss: 0.9162 - val_accuracy: 0.6787\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.8765 - accuracy: 0.6949 - val_loss: 0.8337 - val_accuracy: 0.7136\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.8529 - accuracy: 0.7039 - val_loss: 0.8056 - val_accuracy: 0.7241\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.8319 - accuracy: 0.7100 - val_loss: 0.7990 - val_accuracy: 0.7251\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.8085 - accuracy: 0.7205 - val_loss: 0.7871 - val_accuracy: 0.7308\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.8002 - accuracy: 0.7225 - val_loss: 0.8123 - val_accuracy: 0.7222\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7814 - accuracy: 0.7286 - val_loss: 0.7724 - val_accuracy: 0.7322\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7688 - accuracy: 0.7338 - val_loss: 0.7582 - val_accuracy: 0.7357\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7562 - accuracy: 0.7386 - val_loss: 0.7508 - val_accuracy: 0.7444\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7510 - accuracy: 0.7412 - val_loss: 0.7603 - val_accuracy: 0.7464\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7406 - accuracy: 0.7441 - val_loss: 0.7670 - val_accuracy: 0.7385\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7324 - accuracy: 0.7478 - val_loss: 0.7281 - val_accuracy: 0.7495\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7208 - accuracy: 0.7515 - val_loss: 0.7326 - val_accuracy: 0.7489\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.7167 - accuracy: 0.7536 - val_loss: 0.7210 - val_accuracy: 0.7509\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.7117 - accuracy: 0.7571 - val_loss: 0.7103 - val_accuracy: 0.7572\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 0.7062 - accuracy: 0.7579 - val_loss: 0.7412 - val_accuracy: 0.7488\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.7003 - accuracy: 0.7611 - val_loss: 0.7038 - val_accuracy: 0.7565\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.6965 - accuracy: 0.7635 - val_loss: 0.7186 - val_accuracy: 0.7625\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 0.6903 - accuracy: 0.7651 - val_loss: 0.7228 - val_accuracy: 0.7507\n",
      "Epoch 30/100\n",
      " 799/1563 [==============>...............] - ETA: 27s - loss: 0.6792 - accuracy: 0.7671"
     ]
    }
   ],
   "source": [
    "history = None  # For recording the history of trainning process.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    history = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                    batch_size=batch_size),\n",
    "                                    epochs=epochs,\n",
    "                                    validation_data=(x_test, y_test),\n",
    "                                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db9f45-6bda-43d5-8490-f3da7c5846d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
